{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "trusted": true
   },
   "source": [
    "# <b>IT326: Data mining project\n",
    "# Phase#3:\n",
    "\n",
    "### Check if the data is balanced or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <b>Data Mining Technique </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Classification: </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weâ€™ll run experiments to identify the best way to divide our dataset into training and testing sets. This approach will allow us to determine the ideal ratio, ensuring accurate and dependable model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Splitting Data into: 70% Training and 30% Test</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ <b>Information Gain (entropy):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ DecisionTree :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Confusion matrix :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Splitting evaluation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ <b>Gini Index:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ DecisionTree :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Confusion matrix :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Splitting evaluation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Splitting Data into: 60% Training and 40% Test</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ <b>Information Gain (entropy):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ DecisionTree :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Confusion matrix :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Splitting evaluation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ <b>Gini Index:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ DecisionTree :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Confusion matrix :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Splitting evaluation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Splitting Data into: 80% Training and 20% Test</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ <b>Information Gain (entropy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "clf = clf. fit (X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict (X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ DecisionTree :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 20), dpi=300)\n",
    "\n",
    "\n",
    "class_labels = {0: 'o(low)' , 1:'1(high)'}\n",
    "\n",
    "tree.plot_tree(clf,\n",
    "               feature_names=fn,\n",
    "               class_names=[class_labels[0], class_labels[1]], \n",
    "               filled=True\n",
    "               )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Confusion matrix :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "\n",
    "# Assuming you already have cm, y_test, and y_pred computed\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "class_labels = {0: '0(low)', 1: '1(high)'}\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[class_labels[0], class_labels[1]])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Splitting evaluation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"confusion matrix : \\n\",cm)\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Error Rate is simply 1 minus the Accuracy\n",
    "error_rate = 1 - accuracy\n",
    "print(\"Error Rate:\", error_rate)\n",
    "\n",
    "# Sensitivity (Recall) and Specificity  require TN, FP, FN, TP :\n",
    "\n",
    "TP = cm[1, 1]\n",
    "TN = cm[0, 0]\n",
    "FP = cm[0, 1]\n",
    "FN = cm[1, 0]\n",
    "\n",
    "# Sensitivity (Recall )\n",
    "sensitivity = TP / (TP + FN)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Specificity \n",
    "specificity = TN / (TN + FP)\n",
    "print(\"Specificity:\", specificity)\n",
    "\n",
    "# Precision \n",
    "precision = TP / (TP + FP)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Accuracy: \n",
    "\n",
    "+ Error Rate: \n",
    "\n",
    "+ Sensitivity (True Positive Rate): \n",
    "\n",
    "+ Specificity (True Negative Rate): \n",
    "\n",
    "+ Precision (Positive Predictive Value): \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ <b>Gini Index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "clf = clf. fit (X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict (X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ DecisionTree :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 20), dpi=300)\n",
    "\n",
    "\n",
    "class_labels = {0: 'o(low)' , 1:'1(high)'}\n",
    "\n",
    "tree.plot_tree(clf,\n",
    "               feature_names=fn,\n",
    "               class_names=[class_labels[0], class_labels[1]], \n",
    "               filled=True\n",
    "               )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ confusion matrix :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "\n",
    "# Assuming you already have cm, y_test, and y_pred computed\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "class_labels = {0: '0(low)', 1: '1(high)'}\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[class_labels[0], class_labels[1]])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Splitting evaluation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"confusion matrix : \\n\",cm)\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Error Rate is simply 1 minus the Accuracy\n",
    "error_rate = 1 - accuracy\n",
    "print(\"Error Rate:\", error_rate)\n",
    "\n",
    "# Sensitivity (Recall) and Specificity  require TN, FP, FN, TP :\n",
    "\n",
    "TP = cm[1, 1]\n",
    "TN = cm[0, 0]\n",
    "FP = cm[0, 1]\n",
    "FN = cm[1, 0]\n",
    "\n",
    "# Sensitivity (Recall )\n",
    "sensitivity = TP / (TP + FN)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Specificity \n",
    "specificity = TN / (TN + FP)\n",
    "print(\"Specificity:\", specificity)\n",
    "\n",
    "# Precision \n",
    "precision = TP / (TP + FP)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Accuracy: \n",
    "\n",
    "+ Error Rate: \n",
    "\n",
    "+ Sensitivity (True Positive Rate): \n",
    "\n",
    "+ Specificity (True Negative Rate): \n",
    "\n",
    "+ Precision (Positive Predictive Value): \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluate the models of <b>Information Gain (entropy) :</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Metric</th>\n",
    "      <th>70% Training, 30% Testing</th>\n",
    "      <th>60% Training, 40% Testing</th>\n",
    "      <th>80% Training, 20% Testing</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Accuracy</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Error Rate</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Sensitivity</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Specificity</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Precision</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluate the models of <b>Gini Index :</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Metric</th>\n",
    "      <th>70% Training, 30% Testing</th>\n",
    "      <th>60% Training, 40% Testing</th>\n",
    "      <th>80% Training, 20% Testing</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Accuracy</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Error Rate</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Sensitivity</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Specificity</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Precision</td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "      <td></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pyodide)",
   "language": "python",
   "name": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
